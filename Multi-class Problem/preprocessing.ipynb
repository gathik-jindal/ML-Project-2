{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "821cd9fa",
   "metadata": {},
   "source": [
    "# Preprocessing for the Travel dataset\n",
    "\n",
    "This notebook outlines the steps taken to preprocess the Travel dataset for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f40fb5",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1d920595",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "import warnings\n",
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd09ea91",
   "metadata": {},
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bfa17c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded dataset: train.csv , test.csv\n"
     ]
    }
   ],
   "source": [
    "dataset_dir = Path.cwd().joinpath(\"datasets\")\n",
    "\n",
    "train_dataset = \"train.csv\"\n",
    "test_dataset = \"test.csv\"\n",
    "\n",
    "train_df = pd.read_csv(dataset_dir.joinpath(train_dataset))\n",
    "test_df = pd.read_csv(dataset_dir.joinpath(test_dataset))\n",
    "\n",
    "print(\"Successfully loaded dataset:\", train_dataset, \",\", test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e31cbba",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d05e09f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "EXPLORATORY DATA ANALYSIS for train\n",
      "==================================================\n",
      "\n",
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12654 entries, 0 to 12653\n",
      "Data columns (total 25 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   trip_id                      12654 non-null  object \n",
      " 1   country                      12424 non-null  object \n",
      " 2   age_group                    12646 non-null  object \n",
      " 3   travel_companions            11917 non-null  object \n",
      " 4   num_females                  12652 non-null  float64\n",
      " 5   num_males                    12650 non-null  float64\n",
      " 6   main_activity                12526 non-null  object \n",
      " 7   visit_purpose                12654 non-null  object \n",
      " 8   is_first_visit               12555 non-null  object \n",
      " 9   mainland_stay_nights         12654 non-null  int64  \n",
      " 10  island_stay_nights           12654 non-null  int64  \n",
      " 11  tour_type                    12654 non-null  object \n",
      " 12  intl_transport_included      12507 non-null  object \n",
      " 13  info_source                  12654 non-null  object \n",
      " 14  accomodation_included        12511 non-null  object \n",
      " 15  food_included                12483 non-null  object \n",
      " 16  domestic_transport_included  12654 non-null  object \n",
      " 17  sightseeing_included         12654 non-null  object \n",
      " 18  guide_included               12654 non-null  object \n",
      " 19  insurance_included           12418 non-null  object \n",
      " 20  days_booked_before_trip      11101 non-null  object \n",
      " 21  arrival_weather              9251 non-null   object \n",
      " 22  total_trip_days              12252 non-null  object \n",
      " 23  has_special_requirements     4537 non-null   object \n",
      " 24  spend_category               12620 non-null  float64\n",
      "dtypes: float64(3), int64(2), object(20)\n",
      "memory usage: 2.4+ MB\n",
      "None\n",
      "\n",
      "Dataset Shape: (12654, 25)\n",
      "\n",
      "Statistical Summary:\n",
      "        num_females     num_males  mainland_stay_nights  island_stay_nights  \\\n",
      "count  12652.000000  12650.000000          12654.000000        12654.000000   \n",
      "mean       0.943724      1.009407              9.205073            2.516833   \n",
      "std        1.268167      1.234850             14.548536            5.132266   \n",
      "min        0.000000      0.000000              0.000000            0.000000   \n",
      "25%        0.000000      1.000000              3.000000            0.000000   \n",
      "50%        1.000000      1.000000              6.000000            0.000000   \n",
      "75%        1.000000      1.000000             11.000000            4.000000   \n",
      "max       49.000000     58.000000            365.000000          240.000000   \n",
      "\n",
      "       spend_category  \n",
      "count    12620.000000  \n",
      "mean         0.621157  \n",
      "std          0.683645  \n",
      "min          0.000000  \n",
      "25%          0.000000  \n",
      "50%          1.000000  \n",
      "75%          1.000000  \n",
      "max          2.000000  \n",
      "\n",
      "Missing Values:\n",
      "                          Missing_Count  Percentage\n",
      "has_special_requirements           8117   64.145725\n",
      "arrival_weather                    3403   26.892682\n",
      "days_booked_before_trip            1553   12.272799\n",
      "travel_companions                   737    5.824245\n",
      "total_trip_days                     402    3.176861\n",
      "insurance_included                  236    1.865023\n",
      "country                             230    1.817607\n",
      "food_included                       171    1.351351\n",
      "intl_transport_included             147    1.161688\n",
      "accomodation_included               143    1.130077\n",
      "main_activity                       128    1.011538\n",
      "is_first_visit                       99    0.782361\n",
      "spend_category                       34    0.268690\n",
      "age_group                             8    0.063221\n",
      "num_males                             4    0.031611\n",
      "num_females                           2    0.015805\n",
      "\n",
      "Data Types:\n",
      "object     20\n",
      "float64     3\n",
      "int64       2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Duplicate Rows: 0\n",
      "\n",
      "Unique Values in Categorical Columns:\n",
      "trip_id: 12654 unique values\n",
      "country: 123 unique values\n",
      "age_group: 5 unique values\n",
      "   -> [Low Cardinality] Values: ['45-64', '25-44', '18-24', '65+', 'nan', '<18']\n",
      "travel_companions: 5 unique values\n",
      "   -> [Low Cardinality] Values: ['With Spouse and Children', 'Alone', 'With Other Friends/Relatives', 'With Spouse', 'nan', 'With Children']\n",
      "main_activity: 10 unique values\n",
      "   -> [Low Cardinality] Values: ['Beach Tourism', 'Conference Tourism', 'Cultural Tourism', 'Widlife Tourism', 'Wildlife Tourism', 'Hunting Tourism', 'Mountain Climbing', 'Bird Tourism', 'Business', 'nan', 'Diving and Sport Fishing']\n",
      "visit_purpose: 8 unique values\n",
      "   -> [Low Cardinality] Values: ['Leisure and Holidays', 'Meetings and Conference', 'Business', 'Other', 'Scientific and Academic', 'Visiting Friends and Relatives', 'Volunteering', 'Medical']\n",
      "is_first_visit: 2 unique values\n",
      "   -> [Low Cardinality] Values: ['Yes', 'No', 'nan']\n",
      "tour_type: 2 unique values\n",
      "   -> [Low Cardinality] Values: ['Independent', 'Package Tour']\n",
      "intl_transport_included: 2 unique values\n",
      "   -> [Low Cardinality] Values: ['No', 'Yes', 'nan']\n",
      "info_source: 8 unique values\n",
      "   -> [Low Cardinality] Values: ['Newspaper, magazines, brochures', 'Others', 'Friends, relatives', 'Travel agent, tour operator', 'Radio, TV, Web', 'Mexican Mission Abroad', 'Trade fair', 'Inflight magazines']\n",
      "accomodation_included: 2 unique values\n",
      "   -> [Low Cardinality] Values: ['No', 'Yes', 'nan']\n",
      "food_included: 2 unique values\n",
      "   -> [Low Cardinality] Values: ['No', 'Yes', 'nan']\n",
      "domestic_transport_included: 2 unique values\n",
      "   -> [Low Cardinality] Values: ['No', 'Yes']\n",
      "sightseeing_included: 2 unique values\n",
      "   -> [Low Cardinality] Values: ['No', 'Yes']\n",
      "guide_included: 2 unique values\n",
      "   -> [Low Cardinality] Values: ['No', 'Yes']\n",
      "insurance_included: 2 unique values\n",
      "   -> [Low Cardinality] Values: ['No', 'nan', 'Yes']\n",
      "days_booked_before_trip: 6 unique values\n",
      "   -> [Low Cardinality] Values: ['nan', '15-30 ', '90+', '8-14', '61-90', '31-60', '1-7 ']\n",
      "arrival_weather: 7 unique values\n",
      "   -> [Low Cardinality] Values: ['cloudy,', 'sunny,', 'nan', 'other', 'Rainy', 'Windy,', 'humid', 'Stormy']\n",
      "total_trip_days: 4 unique values\n",
      "   -> [Low Cardinality] Values: ['30+', 'nan', '7-14', '1-6', '15-30']\n",
      "has_special_requirements: 4 unique values\n",
      "   -> [Low Cardinality] Values: ['nan', 'none', 'wheelchair,', 'dietary needs,', 'translator required.']\n",
      "\n",
      "==================================================\n",
      "EXPLORATORY DATA ANALYSIS for test\n",
      "==================================================\n",
      "\n",
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5852 entries, 0 to 5851\n",
      "Data columns (total 24 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   trip_id                      5852 non-null   object \n",
      " 1   country                      5726 non-null   object \n",
      " 2   age_group                    5852 non-null   object \n",
      " 3   travel_companions            5514 non-null   object \n",
      " 4   num_females                  5852 non-null   float64\n",
      " 5   num_males                    5850 non-null   float64\n",
      " 6   main_activity                5787 non-null   object \n",
      " 7   visit_purpose                5852 non-null   object \n",
      " 8   is_first_visit               5813 non-null   object \n",
      " 9   mainland_stay_nights         5852 non-null   int64  \n",
      " 10  island_stay_nights           5852 non-null   int64  \n",
      " 11  tour_type                    5852 non-null   object \n",
      " 12  intl_transport_included      5795 non-null   object \n",
      " 13  info_source                  5852 non-null   object \n",
      " 14  accomodation_included        5790 non-null   object \n",
      " 15  food_included                5774 non-null   object \n",
      " 16  domestic_transport_included  5852 non-null   object \n",
      " 17  sightseeing_included         5852 non-null   object \n",
      " 18  guide_included               5852 non-null   object \n",
      " 19  insurance_included           5745 non-null   object \n",
      " 20  days_booked_before_trip      5185 non-null   object \n",
      " 21  arrival_weather              4259 non-null   object \n",
      " 22  total_trip_days              5699 non-null   object \n",
      " 23  has_special_requirements     2126 non-null   object \n",
      "dtypes: float64(2), int64(2), object(20)\n",
      "memory usage: 1.1+ MB\n",
      "None\n",
      "\n",
      "Dataset Shape: (5852, 24)\n",
      "\n",
      "Statistical Summary:\n",
      "       num_females    num_males  mainland_stay_nights  island_stay_nights\n",
      "count  5852.000000  5850.000000           5852.000000         5852.000000\n",
      "mean      0.920027     0.975726              9.004272            2.443096\n",
      "std       1.093210     1.026954             13.171125            5.571739\n",
      "min       0.000000     0.000000              0.000000            0.000000\n",
      "25%       0.000000     1.000000              3.000000            0.000000\n",
      "50%       1.000000     1.000000              6.000000            0.000000\n",
      "75%       1.000000     1.000000             10.000000            4.000000\n",
      "max      15.000000    24.000000            300.000000          120.000000\n",
      "\n",
      "Missing Values:\n",
      "                          Missing_Count  Percentage\n",
      "has_special_requirements           3726   63.670540\n",
      "arrival_weather                    1593   27.221463\n",
      "days_booked_before_trip             667   11.397813\n",
      "travel_companions                   338    5.775803\n",
      "total_trip_days                     153    2.614491\n",
      "country                             126    2.153110\n",
      "insurance_included                  107    1.828435\n",
      "food_included                        78    1.332878\n",
      "main_activity                        65    1.110731\n",
      "accomodation_included                62    1.059467\n",
      "intl_transport_included              57    0.974026\n",
      "is_first_visit                       39    0.666439\n",
      "num_males                             2    0.034176\n",
      "\n",
      "Data Types:\n",
      "object     20\n",
      "float64     2\n",
      "int64       2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Duplicate Rows: 0\n",
      "\n",
      "Unique Values in Categorical Columns:\n",
      "trip_id: 5852 unique values\n",
      "country: 117 unique values\n",
      "age_group: 5 unique values\n",
      "   -> [Low Cardinality] Values: ['25-44', '45-64', '65+', '18-24', '<18']\n",
      "travel_companions: 5 unique values\n",
      "   -> [Low Cardinality] Values: ['Alone', 'With Spouse', 'With Other Friends/Relatives', 'With Spouse and Children', 'nan', 'With Children']\n",
      "main_activity: 10 unique values\n",
      "   -> [Low Cardinality] Values: ['Widlife Tourism', 'Cultural Tourism', 'Wildlife Tourism', 'Beach Tourism', 'Hunting Tourism', 'Conference Tourism', 'Mountain Climbing', 'Business', 'nan', 'Bird Tourism', 'Diving and Sport Fishing']\n",
      "visit_purpose: 8 unique values\n",
      "   -> [Low Cardinality] Values: ['Business', 'Leisure and Holidays', 'Visiting Friends and Relatives', 'Meetings and Conference', 'Volunteering', 'Scientific and Academic', 'Other', 'Medical']\n",
      "is_first_visit: 2 unique values\n",
      "   -> [Low Cardinality] Values: ['No', 'Yes', 'nan']\n",
      "tour_type: 2 unique values\n",
      "   -> [Low Cardinality] Values: ['Independent', 'Package Tour']\n",
      "intl_transport_included: 2 unique values\n",
      "   -> [Low Cardinality] Values: ['No', 'Yes', 'nan']\n",
      "info_source: 8 unique values\n",
      "   -> [Low Cardinality] Values: ['Friends, relatives', 'Travel agent, tour operator', 'Others', 'Radio, TV, Web', 'Newspaper, magazines, brochures', 'Trade fair', 'Mexican Mission Abroad', 'Inflight magazines']\n",
      "accomodation_included: 2 unique values\n",
      "   -> [Low Cardinality] Values: ['No', 'Yes', 'nan']\n",
      "food_included: 2 unique values\n",
      "   -> [Low Cardinality] Values: ['No', 'Yes', 'nan']\n",
      "domestic_transport_included: 2 unique values\n",
      "   -> [Low Cardinality] Values: ['No', 'Yes']\n",
      "sightseeing_included: 2 unique values\n",
      "   -> [Low Cardinality] Values: ['No', 'Yes']\n",
      "guide_included: 2 unique values\n",
      "   -> [Low Cardinality] Values: ['No', 'Yes']\n",
      "insurance_included: 2 unique values\n",
      "   -> [Low Cardinality] Values: ['No', 'Yes', 'nan']\n",
      "days_booked_before_trip: 6 unique values\n",
      "   -> [Low Cardinality] Values: ['15-30 ', '61-90', '1-7 ', '90+', '31-60', '8-14', 'nan']\n",
      "arrival_weather: 7 unique values\n",
      "   -> [Low Cardinality] Values: ['sunny,', 'Stormy', 'cloudy,', 'nan', 'Rainy', 'Windy,', 'other', 'humid']\n",
      "total_trip_days: 4 unique values\n",
      "   -> [Low Cardinality] Values: ['15-30', '1-6', '30+', '7-14', 'nan']\n",
      "has_special_requirements: 4 unique values\n",
      "   -> [Low Cardinality] Values: ['wheelchair,', 'nan', 'none', 'dietary needs,', 'translator required.']\n"
     ]
    }
   ],
   "source": [
    "def perform_eda(df, save=True, config_file=\"categorical_config.json\"):\n",
    "    \"\"\"\n",
    "    Perform basic exploratory data analysis.\n",
    "    Saves low-cardinality categorical values to a JSON config file.\n",
    "    \"\"\"\n",
    "\n",
    "    # Dataset Info\n",
    "    print(\"\\nDataset Info:\")\n",
    "    print(df.info())\n",
    "\n",
    "    # Shape\n",
    "    print(f\"\\nDataset Shape: {df.shape}\")\n",
    "\n",
    "    # Statistical summary\n",
    "    print(\"\\nStatistical Summary:\")\n",
    "    print(df.describe())\n",
    "\n",
    "    # Missing values\n",
    "    print(\"\\nMissing Values:\")\n",
    "    missing = df.isnull().sum()\n",
    "    missing_pct = (missing / len(df)) * 100\n",
    "    missing_df = pd.DataFrame({\n",
    "        'Missing_Count': missing,\n",
    "        'Percentage': missing_pct\n",
    "    })\n",
    "    print(missing_df[missing_df['Missing_Count'] > 0].sort_values('Missing_Count', ascending=False))\n",
    "\n",
    "    # Data types\n",
    "    print(\"\\nData Types:\")\n",
    "    print(df.dtypes.value_counts())\n",
    "\n",
    "    # Duplicate rows\n",
    "    duplicates = df.duplicated().sum()\n",
    "    print(f\"\\nDuplicate Rows: {duplicates}\")\n",
    "\n",
    "    # --- MODIFIED SECTION START ---\n",
    "    print(\"\\nUnique Values in Categorical Columns:\")\n",
    "    \n",
    "    # Included 'category' dtype as well as object\n",
    "    categorical_cols = df.select_dtypes(include=['object', 'category']).columns\n",
    "    \n",
    "    # Dictionary to store values for the config file\n",
    "    low_cardinality_map = {}\n",
    "\n",
    "    for col in categorical_cols:\n",
    "        unique_count = df[col].nunique()\n",
    "        print(f\"{col}: {unique_count} unique values\")\n",
    "        \n",
    "        # Logic: If less than 20 unique values\n",
    "        if unique_count < 20:\n",
    "            # Get unique values and convert to a standard Python list\n",
    "            # We convert to str to ensure it is JSON serializable (handles np.nan objects)\n",
    "            unique_vals = [str(x) for x in df[col].unique().tolist()]\n",
    "            \n",
    "            # 1. Print them\n",
    "            print(f\"   -> [Low Cardinality] Values: {unique_vals}\")\n",
    "            \n",
    "            # 2. Add to dictionary for saving\n",
    "            low_cardinality_map[col] = unique_vals\n",
    "\n",
    "    # Save to config file if we found any matching columns\n",
    "    if low_cardinality_map and save:\n",
    "        try:\n",
    "            with open(config_file, 'w') as f:\n",
    "                json.dump(low_cardinality_map, f, indent=4)\n",
    "            print(f\"\\n[SUCCESS] Low cardinality categories saved to '{config_file}'\")\n",
    "        except Exception as e:\n",
    "            print(f\"\\n[ERROR] Could not save config file: {e}\")\n",
    "    # --- MODIFIED SECTION END ---\n",
    "\n",
    "    return df\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"EXPLORATORY DATA ANALYSIS for train\")\n",
    "print(\"=\"*50)\n",
    "d = perform_eda(train_df, False)\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"EXPLORATORY DATA ANALYSIS for test\")\n",
    "print(\"=\"*50)\n",
    "d = perform_eda(test_df, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2bbd9d",
   "metadata": {},
   "source": [
    "## Understanding the Dataset\n",
    "\n",
    "Train and Test datasets each have a ton of missing values, most of them are less than 5% missing, but some columns have more than 50% missing values.\n",
    "\n",
    "Two options, drop the values of those columns or impute them.\n",
    "\n",
    "For now, we will drop datapoints for which columns have less than 10% missing values and for columns with more than 10% missing values those columns will be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ae3a6f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "HANDLING MISSING VALUES (Corrected)\n",
      "==================================================\n",
      "Processing TRAIN data...\n",
      "Dropped rows with missing values. New shape: (10492, 25)\n",
      "\n",
      "Missing values after imputation: 10850\n",
      "\n",
      "Missing values after imputation: 0\n",
      "\n",
      "Processing TEST data...\n",
      "Imputed 4 numerical columns with median\n",
      "Imputed 20 categorical columns with mode\n",
      "\n",
      "Missing values after imputation: 0\n",
      "\n",
      "Missing values after imputation: 0\n"
     ]
    }
   ],
   "source": [
    "def handle_missing_values(df, strategy='auto'):\n",
    "    \"\"\"\n",
    "    Handle missing values using different strategies\n",
    "\n",
    "    Parameters:\n",
    "    - strategy: 'auto', 'mean', 'median', 'mode', 'drop', 'drop_column, or custom dict\n",
    "    \"\"\"\n",
    "\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    # Identify numerical and categorical columns\n",
    "    numerical_cols = df_copy.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "    categorical_cols = df_copy.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "    if strategy == 'auto':\n",
    "        # For numerical: use median\n",
    "        if numerical_cols:\n",
    "            num_imputer = SimpleImputer(strategy='median')\n",
    "            df_copy[numerical_cols] = num_imputer.fit_transform(df_copy[numerical_cols])\n",
    "            print(f\"Imputed {len(numerical_cols)} numerical columns with median\")\n",
    "\n",
    "        # For categorical: use mode\n",
    "        if categorical_cols:\n",
    "            for col in categorical_cols:\n",
    "                if df_copy[col].isnull().sum() > 0:\n",
    "                    mode_value = df_copy[col].mode()[0] if len(df_copy[col].mode()) > 0 else 'Unknown'\n",
    "                    df_copy[col].fillna(mode_value, inplace=True)\n",
    "            print(f\"Imputed {len(categorical_cols)} categorical columns with mode\")\n",
    "\n",
    "    elif strategy == 'mean':\n",
    "        num_imputer = SimpleImputer(strategy='mean')\n",
    "        df_copy[numerical_cols] = num_imputer.fit_transform(df_copy[numerical_cols])\n",
    "\n",
    "    elif strategy == 'median':\n",
    "        num_imputer = SimpleImputer(strategy='median')\n",
    "        df_copy[numerical_cols] = num_imputer.fit_transform(df_copy[numerical_cols])\n",
    "\n",
    "    elif strategy == 'drop':\n",
    "        # 1. Calculate the percentage of missing values for each column\n",
    "        null_percentages = df_copy.isnull().mean()\n",
    "\n",
    "        # 2. Identify columns where missing values are less than 10% (0.1)\n",
    "        # We also ensure > 0 to avoid checking columns that are already full\n",
    "        cols_to_check = null_percentages[\n",
    "            (null_percentages < 0.10) & (null_percentages > 0)\n",
    "        ].index\n",
    "\n",
    "        # 3. Drop rows only if they have NaN in those specific columns\n",
    "        df_copy = df_copy.dropna(subset=cols_to_check)\n",
    "        print(f\"Dropped rows with missing values. New shape: {df_copy.shape}\")\n",
    "    \n",
    "    elif strategy == 'drop_column':\n",
    "        # Drop columns with more than 10% missing values\n",
    "        df_copy = df_copy.drop(columns=df_copy.columns[df_copy.isnull().sum() > 0.1 * len(df_copy)])\n",
    "\n",
    "    print(f\"\\nMissing values after imputation: {df_copy.isnull().sum().sum()}\")\n",
    "\n",
    "    return df_copy\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"HANDLING MISSING VALUES (Corrected)\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# --- TRAIN DATA ---\n",
    "# It is okay to drop rows in training if that's your preferred strategy\n",
    "print(\"Processing TRAIN data...\")\n",
    "train_df = handle_missing_values(train_df, strategy='drop')         # Drop rows with missing values\n",
    "train_df = handle_missing_values(train_df, strategy='drop_column')  # Drop columns with too many missing values\n",
    "\n",
    "# --- TEST DATA ---\n",
    "# NEVER drop rows in test data. Use imputation ('auto') instead.\n",
    "print(\"\\nProcessing TEST data...\")\n",
    "test_df = handle_missing_values(test_df, strategy='auto')          # <--- CHANGED: Impute instead of drop\n",
    "test_df = handle_missing_values(test_df, strategy='drop_column')   # Drop columns (risky* see note below)\n",
    "\n",
    "# *NOTE ON DROPPING COLUMNS: \n",
    "# If 'drop_column' removes a column in Train but keeps it in Test (or vice versa), \n",
    "# your model will crash due to mismatched features. \n",
    "# A safer way is to align them at the end:\n",
    "train_cols = train_df.columns.tolist()\n",
    "# Ensure test only has columns that are in train (excluding target 'spend_category')\n",
    "cols_to_keep = [c for c in train_cols if c != 'spend_category']\n",
    "test_df = test_df[cols_to_keep]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb5eafe",
   "metadata": {},
   "source": [
    "## Detecting Outliers\n",
    "\n",
    "We're using the IQR method to detect outliers in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "152c7669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "OUTLIER DETECTION for train dataset\n",
      "==================================================\n",
      "num_females: 568 outliers detected\n",
      "num_males: 3764 outliers detected\n",
      "mainland_stay_nights: 612 outliers detected\n",
      "island_stay_nights: 321 outliers detected\n",
      "spend_category: 0 outliers detected\n",
      "\n",
      "==================================================\n",
      "OUTLIER DETECTION for test dataset\n",
      "==================================================\n",
      "num_females: 302 outliers detected\n",
      "num_males: 2131 outliers detected\n",
      "mainland_stay_nights: 464 outliers detected\n",
      "island_stay_nights: 240 outliers detected\n"
     ]
    }
   ],
   "source": [
    "def detect_outliers_iqr(df, columns=None, threshold=1.5):\n",
    "\n",
    "    if columns is None:\n",
    "        columns = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "    outlier_indices = []\n",
    "\n",
    "    for col in columns:\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "\n",
    "        lower_bound = Q1 - threshold * IQR\n",
    "        upper_bound = Q3 + threshold * IQR\n",
    "\n",
    "        outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)].index\n",
    "        outlier_indices.extend(outliers)\n",
    "\n",
    "        print(f\"{col}: {len(outliers)} outliers detected\")\n",
    "\n",
    "    return list(set(outlier_indices))\n",
    "\n",
    "\"\"\"Detect outliers using IQR method\"\"\"\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"OUTLIER DETECTION for train dataset\")\n",
    "print(\"=\"*50)\n",
    "# indices of outlers in the dataset\n",
    "outliers_train = detect_outliers_iqr(train_df)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"OUTLIER DETECTION for test dataset\")\n",
    "print(\"=\"*50)\n",
    "# indices of outlers in the dataset\n",
    "outliers_test = detect_outliers_iqr(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7ae84c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preprocessed datasets saved to c:\\Users\\gathi\\projects\\ML-Project-2\\Multi-class Problem\\datasets\\preprocessed\n"
     ]
    }
   ],
   "source": [
    "save_dir = dataset_dir.joinpath(\"preprocessed\")\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "train_df.to_csv(save_dir.joinpath(\"train_preprocessed.csv\"), index=False)\n",
    "test_df.to_csv(save_dir.joinpath(\"test_preprocessed.csv\"), index=False)\n",
    "print(f\"\\nPreprocessed datasets saved to {save_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0e5f6f",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "Creating new features based on existing ones to enhance model performance. Do check if you need more features and change code as neccessary.\n",
    "\n",
    "New features created:\n",
    " - age_group split into categogories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a99015e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "EXPLORATORY DATA ANALYSIS for train\n",
      "==================================================\n",
      "\n",
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 10492 entries, 0 to 12652\n",
      "Data columns (total 22 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   trip_id                      10492 non-null  object \n",
      " 1   country                      10492 non-null  object \n",
      " 2   age_group                    10492 non-null  object \n",
      " 3   travel_companions            10492 non-null  object \n",
      " 4   num_females                  10492 non-null  float64\n",
      " 5   num_males                    10492 non-null  float64\n",
      " 6   main_activity                10492 non-null  object \n",
      " 7   visit_purpose                10492 non-null  object \n",
      " 8   is_first_visit               10492 non-null  object \n",
      " 9   mainland_stay_nights         10492 non-null  int64  \n",
      " 10  island_stay_nights           10492 non-null  int64  \n",
      " 11  tour_type                    10492 non-null  object \n",
      " 12  intl_transport_included      10492 non-null  object \n",
      " 13  info_source                  10492 non-null  object \n",
      " 14  accomodation_included        10492 non-null  object \n",
      " 15  food_included                10492 non-null  object \n",
      " 16  domestic_transport_included  10492 non-null  object \n",
      " 17  sightseeing_included         10492 non-null  object \n",
      " 18  guide_included               10492 non-null  object \n",
      " 19  insurance_included           10492 non-null  object \n",
      " 20  total_trip_days              10492 non-null  object \n",
      " 21  spend_category               10492 non-null  float64\n",
      "dtypes: float64(3), int64(2), object(17)\n",
      "memory usage: 1.8+ MB\n",
      "None\n",
      "\n",
      "Dataset Shape: (10492, 22)\n",
      "\n",
      "Statistical Summary:\n",
      "        num_females     num_males  mainland_stay_nights  island_stay_nights  \\\n",
      "count  10492.000000  10492.000000          10492.000000        10492.000000   \n",
      "mean       0.973313      1.030499              9.132863            2.588448   \n",
      "std        1.275452      1.186869             15.023836            5.190645   \n",
      "min        0.000000      0.000000              0.000000            0.000000   \n",
      "25%        0.000000      1.000000              3.000000            0.000000   \n",
      "50%        1.000000      1.000000              6.000000            0.000000   \n",
      "75%        1.000000      1.000000             11.000000            5.000000   \n",
      "max       49.000000     44.000000            365.000000          240.000000   \n",
      "\n",
      "       spend_category  \n",
      "count    10492.000000  \n",
      "mean         0.600267  \n",
      "std          0.677225  \n",
      "min          0.000000  \n",
      "25%          0.000000  \n",
      "50%          0.000000  \n",
      "75%          1.000000  \n",
      "max          2.000000  \n",
      "\n",
      "Missing Values:\n",
      "Empty DataFrame\n",
      "Columns: [Missing_Count, Percentage]\n",
      "Index: []\n",
      "\n",
      "Data Types:\n",
      "object     17\n",
      "float64     3\n",
      "int64       2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Duplicate Rows: 0\n",
      "\n",
      "Unique Values in Categorical Columns:\n",
      "trip_id: 10492 unique values\n",
      "country: 120 unique values\n",
      "age_group: 5 unique values\n",
      "   -> [Low Cardinality] Values: ['45-64', '25-44', '18-24', '65+', '<18']\n",
      "travel_companions: 5 unique values\n",
      "   -> [Low Cardinality] Values: ['With Spouse and Children', 'Alone', 'With Other Friends/Relatives', 'With Spouse', 'With Children']\n",
      "main_activity: 10 unique values\n",
      "   -> [Low Cardinality] Values: ['Beach Tourism', 'Conference Tourism', 'Cultural Tourism', 'Wildlife Tourism', 'Hunting Tourism', 'Widlife Tourism', 'Mountain Climbing', 'Bird Tourism', 'Business', 'Diving and Sport Fishing']\n",
      "visit_purpose: 8 unique values\n",
      "   -> [Low Cardinality] Values: ['Leisure and Holidays', 'Meetings and Conference', 'Business', 'Scientific and Academic', 'Visiting Friends and Relatives', 'Other', 'Volunteering', 'Medical']\n",
      "is_first_visit: 2 unique values\n",
      "   -> [Low Cardinality] Values: ['Yes', 'No']\n",
      "tour_type: 2 unique values\n",
      "   -> [Low Cardinality] Values: ['Independent', 'Package Tour']\n",
      "intl_transport_included: 2 unique values\n",
      "   -> [Low Cardinality] Values: ['No', 'Yes']\n",
      "info_source: 8 unique values\n",
      "   -> [Low Cardinality] Values: ['Newspaper, magazines, brochures', 'Others', 'Friends, relatives', 'Travel agent, tour operator', 'Mexican Mission Abroad', 'Radio, TV, Web', 'Trade fair', 'Inflight magazines']\n",
      "accomodation_included: 2 unique values\n",
      "   -> [Low Cardinality] Values: ['No', 'Yes']\n",
      "food_included: 2 unique values\n",
      "   -> [Low Cardinality] Values: ['No', 'Yes']\n",
      "domestic_transport_included: 2 unique values\n",
      "   -> [Low Cardinality] Values: ['No', 'Yes']\n",
      "sightseeing_included: 2 unique values\n",
      "   -> [Low Cardinality] Values: ['No', 'Yes']\n",
      "guide_included: 2 unique values\n",
      "   -> [Low Cardinality] Values: ['No', 'Yes']\n",
      "insurance_included: 2 unique values\n",
      "   -> [Low Cardinality] Values: ['No', 'Yes']\n",
      "total_trip_days: 4 unique values\n",
      "   -> [Low Cardinality] Values: ['30+', '7-14', '15-30', '1-6']\n",
      "\n",
      "[SUCCESS] Low cardinality categories saved to 'categorical_config.json'\n",
      "\n",
      "==================================================\n",
      "EXPLORATORY DATA ANALYSIS for test\n",
      "==================================================\n",
      "\n",
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5852 entries, 0 to 5851\n",
      "Data columns (total 21 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   trip_id                      5852 non-null   object \n",
      " 1   country                      5852 non-null   object \n",
      " 2   age_group                    5852 non-null   object \n",
      " 3   travel_companions            5852 non-null   object \n",
      " 4   num_females                  5852 non-null   float64\n",
      " 5   num_males                    5852 non-null   float64\n",
      " 6   main_activity                5852 non-null   object \n",
      " 7   visit_purpose                5852 non-null   object \n",
      " 8   is_first_visit               5852 non-null   object \n",
      " 9   mainland_stay_nights         5852 non-null   float64\n",
      " 10  island_stay_nights           5852 non-null   float64\n",
      " 11  tour_type                    5852 non-null   object \n",
      " 12  intl_transport_included      5852 non-null   object \n",
      " 13  info_source                  5852 non-null   object \n",
      " 14  accomodation_included        5852 non-null   object \n",
      " 15  food_included                5852 non-null   object \n",
      " 16  domestic_transport_included  5852 non-null   object \n",
      " 17  sightseeing_included         5852 non-null   object \n",
      " 18  guide_included               5852 non-null   object \n",
      " 19  insurance_included           5852 non-null   object \n",
      " 20  total_trip_days              5852 non-null   object \n",
      "dtypes: float64(4), object(17)\n",
      "memory usage: 960.2+ KB\n",
      "None\n",
      "\n",
      "Dataset Shape: (5852, 21)\n",
      "\n",
      "Statistical Summary:\n",
      "       num_females    num_males  mainland_stay_nights  island_stay_nights\n",
      "count  5852.000000  5852.000000           5852.000000         5852.000000\n",
      "mean      0.920027     0.975735              9.004272            2.443096\n",
      "std       1.093210     1.026778             13.171125            5.571739\n",
      "min       0.000000     0.000000              0.000000            0.000000\n",
      "25%       0.000000     1.000000              3.000000            0.000000\n",
      "50%       1.000000     1.000000              6.000000            0.000000\n",
      "75%       1.000000     1.000000             10.000000            4.000000\n",
      "max      15.000000    24.000000            300.000000          120.000000\n",
      "\n",
      "Missing Values:\n",
      "Empty DataFrame\n",
      "Columns: [Missing_Count, Percentage]\n",
      "Index: []\n",
      "\n",
      "Data Types:\n",
      "object     17\n",
      "float64     4\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Duplicate Rows: 0\n",
      "\n",
      "Unique Values in Categorical Columns:\n",
      "trip_id: 5852 unique values\n",
      "country: 117 unique values\n",
      "age_group: 5 unique values\n",
      "   -> [Low Cardinality] Values: ['25-44', '45-64', '65+', '18-24', '<18']\n",
      "travel_companions: 5 unique values\n",
      "   -> [Low Cardinality] Values: ['Alone', 'With Spouse', 'With Other Friends/Relatives', 'With Spouse and Children', 'With Children']\n",
      "main_activity: 10 unique values\n",
      "   -> [Low Cardinality] Values: ['Widlife Tourism', 'Cultural Tourism', 'Wildlife Tourism', 'Beach Tourism', 'Hunting Tourism', 'Conference Tourism', 'Mountain Climbing', 'Business', 'Bird Tourism', 'Diving and Sport Fishing']\n",
      "visit_purpose: 8 unique values\n",
      "   -> [Low Cardinality] Values: ['Business', 'Leisure and Holidays', 'Visiting Friends and Relatives', 'Meetings and Conference', 'Volunteering', 'Scientific and Academic', 'Other', 'Medical']\n",
      "is_first_visit: 2 unique values\n",
      "   -> [Low Cardinality] Values: ['No', 'Yes']\n",
      "tour_type: 2 unique values\n",
      "   -> [Low Cardinality] Values: ['Independent', 'Package Tour']\n",
      "intl_transport_included: 2 unique values\n",
      "   -> [Low Cardinality] Values: ['No', 'Yes']\n",
      "info_source: 8 unique values\n",
      "   -> [Low Cardinality] Values: ['Friends, relatives', 'Travel agent, tour operator', 'Others', 'Radio, TV, Web', 'Newspaper, magazines, brochures', 'Trade fair', 'Mexican Mission Abroad', 'Inflight magazines']\n",
      "accomodation_included: 2 unique values\n",
      "   -> [Low Cardinality] Values: ['No', 'Yes']\n",
      "food_included: 2 unique values\n",
      "   -> [Low Cardinality] Values: ['No', 'Yes']\n",
      "domestic_transport_included: 2 unique values\n",
      "   -> [Low Cardinality] Values: ['No', 'Yes']\n",
      "sightseeing_included: 2 unique values\n",
      "   -> [Low Cardinality] Values: ['No', 'Yes']\n",
      "guide_included: 2 unique values\n",
      "   -> [Low Cardinality] Values: ['No', 'Yes']\n",
      "insurance_included: 2 unique values\n",
      "   -> [Low Cardinality] Values: ['No', 'Yes']\n",
      "total_trip_days: 4 unique values\n",
      "   -> [Low Cardinality] Values: ['15-30', '1-6', '30+', '7-14']\n",
      "\n",
      "[SUCCESS] Low cardinality categories saved to 'categorical_config.json'\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"EXPLORATORY DATA ANALYSIS for train\")\n",
    "print(\"=\"*50)\n",
    "d = perform_eda(train_df)\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"EXPLORATORY DATA ANALYSIS for test\")\n",
    "print(\"=\"*50)\n",
    "d = perform_eda(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17092aaf",
   "metadata": {},
   "source": [
    "## Things left to do\n",
    "\n",
    "Do the following preprocessing steps based on your requirements.\n",
    "\n",
    "1) Feature Engineering\n",
    "2) Feature Encoding\n",
    "4) Encoding Categorical Variables\n",
    "3) Feature Scaling\n",
    "4) Feature Selection\n",
    "5) Data Validation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
