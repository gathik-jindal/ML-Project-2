{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "821cd9fa",
   "metadata": {},
   "source": [
    "# Preprocessing for the Travel dataset\n",
    "\n",
    "This notebook outlines the steps taken to preprocess the Travel dataset for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f40fb5",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d920595",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "import warnings\n",
    "import os\n",
    "from pathlib import Path\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd09ea91",
   "metadata": {},
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfa17c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded dataset: train.csv , test.csv\n"
     ]
    }
   ],
   "source": [
    "dataset_dir = Path.cwd().joinpath(\"datasets\")\n",
    "\n",
    "train_dataset = \"train.csv\"\n",
    "test_dataset = \"test.csv\"\n",
    "\n",
    "train_df = pd.read_csv(dataset_dir.joinpath(train_dataset))\n",
    "test_df = pd.read_csv(dataset_dir.joinpath(test_dataset))\n",
    "\n",
    "print(\"Successfully loaded dataset:\", train_dataset, \",\", test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e31cbba",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d05e09f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "EXPLORATORY DATA ANALYSIS for train\n",
      "==================================================\n",
      "\n",
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 204277 entries, 0 to 204276\n",
      "Data columns (total 18 columns):\n",
      " #   Column              Non-Null Count   Dtype  \n",
      "---  ------              --------------   -----  \n",
      " 0   ProfileID           204277 non-null  object \n",
      " 1   ApplicantYears      204277 non-null  int64  \n",
      " 2   AnnualEarnings      204277 non-null  int64  \n",
      " 3   RequestedSum        204277 non-null  int64  \n",
      " 4   TrustMetric         204277 non-null  int64  \n",
      " 5   WorkDuration        204277 non-null  int64  \n",
      " 6   ActiveAccounts      204277 non-null  int64  \n",
      " 7   OfferRate           204277 non-null  float64\n",
      " 8   RepayPeriod         204277 non-null  int64  \n",
      " 9   DebtFactor          204277 non-null  float64\n",
      " 10  QualificationLevel  204277 non-null  object \n",
      " 11  WorkCategory        204277 non-null  object \n",
      " 12  RelationshipStatus  204277 non-null  object \n",
      " 13  OwnsProperty        204277 non-null  object \n",
      " 14  FamilyObligation    204277 non-null  object \n",
      " 15  FundUseCase         204277 non-null  object \n",
      " 16  JointApplicant      204277 non-null  object \n",
      " 17  RiskFlag            204277 non-null  int64  \n",
      "dtypes: float64(2), int64(8), object(8)\n",
      "memory usage: 28.1+ MB\n",
      "None\n",
      "\n",
      "Dataset Shape: (204277, 18)\n",
      "\n",
      "Statistical Summary:\n",
      "       ApplicantYears  AnnualEarnings   RequestedSum    TrustMetric  \\\n",
      "count   204277.000000   204277.000000  204277.000000  204277.000000   \n",
      "mean        43.489340    82506.227980  127547.496395     574.075500   \n",
      "std         14.995191    38952.103374   70855.064746     158.877098   \n",
      "min         18.000000    15000.000000    5001.000000     300.000000   \n",
      "25%         31.000000    48878.000000   66059.000000     437.000000   \n",
      "50%         43.000000    82400.000000  127603.000000     574.000000   \n",
      "75%         56.000000   116247.000000  188843.000000     712.000000   \n",
      "max         69.000000   149999.000000  249999.000000     849.000000   \n",
      "\n",
      "        WorkDuration  ActiveAccounts      OfferRate    RepayPeriod  \\\n",
      "count  204277.000000   204277.000000  204277.000000  204277.000000   \n",
      "mean       59.508511        2.502078      13.488147      36.010926   \n",
      "std        34.645589        1.116898       6.636060      16.944827   \n",
      "min         0.000000        1.000000       2.000000      12.000000   \n",
      "25%        30.000000        2.000000       7.760000      24.000000   \n",
      "50%        59.000000        3.000000      13.450000      36.000000   \n",
      "75%        90.000000        4.000000      19.240000      48.000000   \n",
      "max       119.000000        4.000000      25.000000      60.000000   \n",
      "\n",
      "          DebtFactor       RiskFlag  \n",
      "count  204277.000000  204277.000000  \n",
      "mean        0.500579       0.116278  \n",
      "std         0.230914       0.320559  \n",
      "min         0.100000       0.000000  \n",
      "25%         0.300000       0.000000  \n",
      "50%         0.500000       0.000000  \n",
      "75%         0.700000       0.000000  \n",
      "max         0.900000       1.000000  \n",
      "\n",
      "Missing Values:\n",
      "Empty DataFrame\n",
      "Columns: [Missing_Count, Percentage]\n",
      "Index: []\n",
      "\n",
      "Data Types:\n",
      "object     8\n",
      "int64      8\n",
      "float64    2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Duplicate Rows: 0\n",
      "\n",
      "Unique Values in Categorical Columns:\n",
      "ProfileID: 204277 unique values\n",
      "QualificationLevel: 4 unique values\n",
      "WorkCategory: 4 unique values\n",
      "RelationshipStatus: 3 unique values\n",
      "OwnsProperty: 2 unique values\n",
      "FamilyObligation: 2 unique values\n",
      "FundUseCase: 5 unique values\n",
      "JointApplicant: 2 unique values\n",
      "\n",
      "==================================================\n",
      "EXPLORATORY DATA ANALYSIS for test\n",
      "==================================================\n",
      "\n",
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 51070 entries, 0 to 51069\n",
      "Data columns (total 17 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   ProfileID           51070 non-null  object \n",
      " 1   ApplicantYears      51070 non-null  int64  \n",
      " 2   AnnualEarnings      51070 non-null  int64  \n",
      " 3   RequestedSum        51070 non-null  int64  \n",
      " 4   TrustMetric         51070 non-null  int64  \n",
      " 5   WorkDuration        51070 non-null  int64  \n",
      " 6   ActiveAccounts      51070 non-null  int64  \n",
      " 7   OfferRate           51070 non-null  float64\n",
      " 8   RepayPeriod         51070 non-null  int64  \n",
      " 9   DebtFactor          51070 non-null  float64\n",
      " 10  QualificationLevel  51070 non-null  object \n",
      " 11  WorkCategory        51070 non-null  object \n",
      " 12  RelationshipStatus  51070 non-null  object \n",
      " 13  OwnsProperty        51070 non-null  object \n",
      " 14  FamilyObligation    51070 non-null  object \n",
      " 15  FundUseCase         51070 non-null  object \n",
      " 16  JointApplicant      51070 non-null  object \n",
      "dtypes: float64(2), int64(7), object(8)\n",
      "memory usage: 6.6+ MB\n",
      "None\n",
      "\n",
      "Dataset Shape: (51070, 17)\n",
      "\n",
      "Statistical Summary:\n",
      "       ApplicantYears  AnnualEarnings   RequestedSum   TrustMetric  \\\n",
      "count    51070.000000    51070.000000   51070.000000  51070.000000   \n",
      "mean        43.534169    82471.611474  127704.340141    575.019718   \n",
      "std         14.970605    39006.993391   70783.797718    159.010208   \n",
      "min         18.000000    15000.000000    5000.000000    300.000000   \n",
      "25%         31.000000    48616.750000   66506.250000    437.000000   \n",
      "50%         43.000000    82686.500000  127330.000000    575.000000   \n",
      "75%         57.000000   116136.250000  189465.750000    713.000000   \n",
      "max         69.000000   149994.000000  249986.000000    849.000000   \n",
      "\n",
      "       WorkDuration  ActiveAccounts     OfferRate   RepayPeriod    DebtFactor  \n",
      "count  51070.000000    51070.000000  51070.000000  51070.000000  51070.000000  \n",
      "mean      59.675837        2.496867     13.511278     36.085765      0.498745  \n",
      "std       34.634536        1.117497      6.638008     17.067022      0.230924  \n",
      "min        0.000000        1.000000      2.000000     12.000000      0.100000  \n",
      "25%       30.000000        1.000000      7.800000     24.000000      0.300000  \n",
      "50%       60.000000        2.000000     13.480000     36.000000      0.500000  \n",
      "75%       90.000000        3.000000     19.280000     48.000000      0.700000  \n",
      "max      119.000000        4.000000     25.000000     60.000000      0.900000  \n",
      "\n",
      "Missing Values:\n",
      "Empty DataFrame\n",
      "Columns: [Missing_Count, Percentage]\n",
      "Index: []\n",
      "\n",
      "Data Types:\n",
      "object     8\n",
      "int64      7\n",
      "float64    2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Duplicate Rows: 0\n",
      "\n",
      "Unique Values in Categorical Columns:\n",
      "ProfileID: 51070 unique values\n",
      "QualificationLevel: 4 unique values\n",
      "WorkCategory: 4 unique values\n",
      "RelationshipStatus: 3 unique values\n",
      "OwnsProperty: 2 unique values\n",
      "FamilyObligation: 2 unique values\n",
      "FundUseCase: 5 unique values\n",
      "JointApplicant: 2 unique values\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProfileID</th>\n",
       "      <th>ApplicantYears</th>\n",
       "      <th>AnnualEarnings</th>\n",
       "      <th>RequestedSum</th>\n",
       "      <th>TrustMetric</th>\n",
       "      <th>WorkDuration</th>\n",
       "      <th>ActiveAccounts</th>\n",
       "      <th>OfferRate</th>\n",
       "      <th>RepayPeriod</th>\n",
       "      <th>DebtFactor</th>\n",
       "      <th>QualificationLevel</th>\n",
       "      <th>WorkCategory</th>\n",
       "      <th>RelationshipStatus</th>\n",
       "      <th>OwnsProperty</th>\n",
       "      <th>FamilyObligation</th>\n",
       "      <th>FundUseCase</th>\n",
       "      <th>JointApplicant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CKV34LU7V7</td>\n",
       "      <td>55</td>\n",
       "      <td>112656</td>\n",
       "      <td>92393</td>\n",
       "      <td>581</td>\n",
       "      <td>113</td>\n",
       "      <td>2</td>\n",
       "      <td>23.54</td>\n",
       "      <td>36</td>\n",
       "      <td>0.15</td>\n",
       "      <td>PhD</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Single</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Home</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62KTYNH93J</td>\n",
       "      <td>56</td>\n",
       "      <td>91569</td>\n",
       "      <td>131575</td>\n",
       "      <td>641</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>15.19</td>\n",
       "      <td>12</td>\n",
       "      <td>0.43</td>\n",
       "      <td>High School</td>\n",
       "      <td>Part-time</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Education</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JGFUSOIUH7</td>\n",
       "      <td>26</td>\n",
       "      <td>78169</td>\n",
       "      <td>75417</td>\n",
       "      <td>569</td>\n",
       "      <td>105</td>\n",
       "      <td>3</td>\n",
       "      <td>18.02</td>\n",
       "      <td>12</td>\n",
       "      <td>0.29</td>\n",
       "      <td>Master's</td>\n",
       "      <td>Part-time</td>\n",
       "      <td>Married</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Education</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4538THBHOX</td>\n",
       "      <td>26</td>\n",
       "      <td>63033</td>\n",
       "      <td>10804</td>\n",
       "      <td>326</td>\n",
       "      <td>118</td>\n",
       "      <td>1</td>\n",
       "      <td>14.71</td>\n",
       "      <td>24</td>\n",
       "      <td>0.41</td>\n",
       "      <td>High School</td>\n",
       "      <td>Part-time</td>\n",
       "      <td>Single</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Business</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DXLNA06JHR</td>\n",
       "      <td>24</td>\n",
       "      <td>29665</td>\n",
       "      <td>21182</td>\n",
       "      <td>662</td>\n",
       "      <td>102</td>\n",
       "      <td>3</td>\n",
       "      <td>15.02</td>\n",
       "      <td>60</td>\n",
       "      <td>0.69</td>\n",
       "      <td>PhD</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>Single</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Business</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51065</th>\n",
       "      <td>DQRTA8KWGC</td>\n",
       "      <td>51</td>\n",
       "      <td>99473</td>\n",
       "      <td>170353</td>\n",
       "      <td>628</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>17.03</td>\n",
       "      <td>12</td>\n",
       "      <td>0.46</td>\n",
       "      <td>PhD</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Auto</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51066</th>\n",
       "      <td>W0FDMPACG3</td>\n",
       "      <td>29</td>\n",
       "      <td>42016</td>\n",
       "      <td>111314</td>\n",
       "      <td>371</td>\n",
       "      <td>51</td>\n",
       "      <td>4</td>\n",
       "      <td>7.10</td>\n",
       "      <td>36</td>\n",
       "      <td>0.50</td>\n",
       "      <td>PhD</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Married</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Other</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51067</th>\n",
       "      <td>MA0F4U8ORY</td>\n",
       "      <td>67</td>\n",
       "      <td>88507</td>\n",
       "      <td>142666</td>\n",
       "      <td>731</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>22.89</td>\n",
       "      <td>48</td>\n",
       "      <td>0.79</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>Part-time</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Education</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51068</th>\n",
       "      <td>6QUH04P7EJ</td>\n",
       "      <td>42</td>\n",
       "      <td>116649</td>\n",
       "      <td>190938</td>\n",
       "      <td>488</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>10.83</td>\n",
       "      <td>60</td>\n",
       "      <td>0.32</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Married</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Other</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51069</th>\n",
       "      <td>GTCED2IEL9</td>\n",
       "      <td>49</td>\n",
       "      <td>90420</td>\n",
       "      <td>83956</td>\n",
       "      <td>752</td>\n",
       "      <td>73</td>\n",
       "      <td>2</td>\n",
       "      <td>5.64</td>\n",
       "      <td>24</td>\n",
       "      <td>0.56</td>\n",
       "      <td>Master's</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>Married</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Education</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51070 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ProfileID  ApplicantYears  AnnualEarnings  RequestedSum  TrustMetric  \\\n",
       "0      CKV34LU7V7              55          112656         92393          581   \n",
       "1      62KTYNH93J              56           91569        131575          641   \n",
       "2      JGFUSOIUH7              26           78169         75417          569   \n",
       "3      4538THBHOX              26           63033         10804          326   \n",
       "4      DXLNA06JHR              24           29665         21182          662   \n",
       "...           ...             ...             ...           ...          ...   \n",
       "51065  DQRTA8KWGC              51           99473        170353          628   \n",
       "51066  W0FDMPACG3              29           42016        111314          371   \n",
       "51067  MA0F4U8ORY              67           88507        142666          731   \n",
       "51068  6QUH04P7EJ              42          116649        190938          488   \n",
       "51069  GTCED2IEL9              49           90420         83956          752   \n",
       "\n",
       "       WorkDuration  ActiveAccounts  OfferRate  RepayPeriod  DebtFactor  \\\n",
       "0               113               2      23.54           36        0.15   \n",
       "1                54               1      15.19           12        0.43   \n",
       "2               105               3      18.02           12        0.29   \n",
       "3               118               1      14.71           24        0.41   \n",
       "4               102               3      15.02           60        0.69   \n",
       "...             ...             ...        ...          ...         ...   \n",
       "51065            24               1      17.03           12        0.46   \n",
       "51066            51               4       7.10           36        0.50   \n",
       "51067            51               1      22.89           48        0.79   \n",
       "51068             6               1      10.83           60        0.32   \n",
       "51069            73               2       5.64           24        0.56   \n",
       "\n",
       "      QualificationLevel   WorkCategory RelationshipStatus OwnsProperty  \\\n",
       "0                    PhD  Self-employed             Single          Yes   \n",
       "1            High School      Part-time           Divorced          Yes   \n",
       "2               Master's      Part-time            Married          Yes   \n",
       "3            High School      Part-time             Single           No   \n",
       "4                    PhD     Unemployed             Single           No   \n",
       "...                  ...            ...                ...          ...   \n",
       "51065                PhD  Self-employed           Divorced          Yes   \n",
       "51066                PhD  Self-employed            Married           No   \n",
       "51067         Bachelor's      Part-time           Divorced           No   \n",
       "51068         Bachelor's      Full-time            Married           No   \n",
       "51069           Master's     Unemployed            Married          Yes   \n",
       "\n",
       "      FamilyObligation FundUseCase JointApplicant  \n",
       "0                  Yes        Home             No  \n",
       "1                  Yes   Education            Yes  \n",
       "2                  Yes   Education            Yes  \n",
       "3                   No    Business            Yes  \n",
       "4                  Yes    Business            Yes  \n",
       "...                ...         ...            ...  \n",
       "51065              Yes        Auto            Yes  \n",
       "51066               No       Other             No  \n",
       "51067               No   Education             No  \n",
       "51068              Yes       Other            Yes  \n",
       "51069               No   Education             No  \n",
       "\n",
       "[51070 rows x 17 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def perform_eda(df):\n",
    "    \"\"\"Perform basic exploratory data analysis\"\"\"\n",
    "\n",
    "    # Dataset Info\n",
    "    print(\"\\nDataset Info:\")\n",
    "    print(df.info())\n",
    "\n",
    "    # Shape\n",
    "    print(f\"\\nDataset Shape: {df.shape}\")\n",
    "\n",
    "    # First few rows\n",
    "    # print(\"\\nFirst 5 rows:\")\n",
    "    # print(df.head())\n",
    "\n",
    "    # Statistical summary\n",
    "    print(\"\\nStatistical Summary:\")\n",
    "    print(df.describe())\n",
    "\n",
    "    # Missing values\n",
    "    print(\"\\nMissing Values:\")\n",
    "    missing = df.isnull().sum()\n",
    "    missing_pct = (missing / len(df)) * 100\n",
    "    missing_df = pd.DataFrame({\n",
    "        'Missing_Count': missing,\n",
    "        'Percentage': missing_pct\n",
    "    })\n",
    "    print(missing_df[missing_df['Missing_Count'] > 0].sort_values('Missing_Count', ascending=False))\n",
    "\n",
    "    # Data types\n",
    "    print(\"\\nData Types:\")\n",
    "    print(df.dtypes.value_counts())\n",
    "\n",
    "    # Duplicate rows\n",
    "    duplicates = df.duplicated().sum()\n",
    "    print(f\"\\nDuplicate Rows: {duplicates}\")\n",
    "\n",
    "    # Unique values for categorical columns\n",
    "    print(\"\\nUnique Values in Categorical Columns:\")\n",
    "    categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "    for col in categorical_cols:\n",
    "        print(f\"{col}: {df[col].nunique()} unique values\")\n",
    "\n",
    "    return df\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"EXPLORATORY DATA ANALYSIS for train\")\n",
    "print(\"=\"*50)\n",
    "perform_eda(train_df)\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"EXPLORATORY DATA ANALYSIS for test\")\n",
    "print(\"=\"*50)\n",
    "perform_eda(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2bbd9d",
   "metadata": {},
   "source": [
    "## Understanding the Dataset\n",
    "\n",
    "Train and Test datasets each have a ton of missing values, most of them are less than 5% missing, but some columns have more than 50% missing values.\n",
    "\n",
    "Two options, drop the values of those columns or impute them.\n",
    "\n",
    "For now, we will drop datapoints for which columns have less than 10% missing values and for columns with more than 10% missing values those columns will be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae3a6f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "HANDLING MISSING VALUES for train and test datasets\n",
      "==================================================\n",
      "Dropped rows with missing values. New shape: (204277, 18)\n",
      "\n",
      "Missing values after imputation: 0\n",
      "\n",
      "Missing values after imputation: 0\n",
      "\n",
      "Doing for test now\n",
      "\n",
      "Dropped rows with missing values. New shape: (51070, 17)\n",
      "\n",
      "Missing values after imputation: 0\n",
      "\n",
      "Missing values after imputation: 0\n"
     ]
    }
   ],
   "source": [
    "def handle_missing_values(df, strategy='auto'):\n",
    "    \"\"\"\n",
    "    Handle missing values using different strategies\n",
    "\n",
    "    Parameters:\n",
    "    - strategy: 'auto', 'mean', 'median', 'mode', 'drop', 'drop_column, or custom dict\n",
    "    \"\"\"\n",
    "\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    # Identify numerical and categorical columns\n",
    "    numerical_cols = df_copy.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "    categorical_cols = df_copy.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "    if strategy == 'auto':\n",
    "        # For numerical: use median\n",
    "        if numerical_cols:\n",
    "            num_imputer = SimpleImputer(strategy='median')\n",
    "            df_copy[numerical_cols] = num_imputer.fit_transform(df_copy[numerical_cols])\n",
    "            print(f\"Imputed {len(numerical_cols)} numerical columns with median\")\n",
    "\n",
    "        # For categorical: use mode\n",
    "        if categorical_cols:\n",
    "            for col in categorical_cols:\n",
    "                if df_copy[col].isnull().sum() > 0:\n",
    "                    mode_value = df_copy[col].mode()[0] if len(df_copy[col].mode()) > 0 else 'Unknown'\n",
    "                    df_copy[col].fillna(mode_value, inplace=True)\n",
    "            print(f\"Imputed {len(categorical_cols)} categorical columns with mode\")\n",
    "\n",
    "    elif strategy == 'mean':\n",
    "        num_imputer = SimpleImputer(strategy='mean')\n",
    "        df_copy[numerical_cols] = num_imputer.fit_transform(df_copy[numerical_cols])\n",
    "\n",
    "    elif strategy == 'median':\n",
    "        num_imputer = SimpleImputer(strategy='median')\n",
    "        df_copy[numerical_cols] = num_imputer.fit_transform(df_copy[numerical_cols])\n",
    "\n",
    "    elif strategy == 'drop':\n",
    "        # 1. Calculate the percentage of missing values for each column\n",
    "        null_percentages = df_copy.isnull().mean()\n",
    "\n",
    "        # 2. Identify columns where missing values are less than 10% (0.1)\n",
    "        # We also ensure > 0 to avoid checking columns that are already full\n",
    "        cols_to_check = null_percentages[\n",
    "            (null_percentages < 0.10) & (null_percentages > 0)\n",
    "        ].index\n",
    "\n",
    "        # 3. Drop rows only if they have NaN in those specific columns\n",
    "        df_copy = df_copy.dropna(subset=cols_to_check)\n",
    "        print(f\"Dropped rows with missing values. New shape: {df_copy.shape}\")\n",
    "    \n",
    "    elif strategy == 'drop_column':\n",
    "        # Drop columns with more than 10% missing values\n",
    "        df_copy = df_copy.drop(columns=df_copy.columns[df_copy.isnull().sum() > 0.1 * len(df_copy)])\n",
    "\n",
    "    print(f\"\\nMissing values after imputation: {df_copy.isnull().sum().sum()}\")\n",
    "\n",
    "    return df_copy\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"HANDLING MISSING VALUES for train and test datasets\")\n",
    "print(\"=\"*50)\n",
    "train_df = handle_missing_values(handle_missing_values(train_df, strategy='drop'), strategy='drop_column')\n",
    "print(\"\\nDoing for test now\\n\")\n",
    "test_df = handle_missing_values(handle_missing_values(test_df, strategy='drop'), strategy='drop_column')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb5eafe",
   "metadata": {},
   "source": [
    "## Detecting Outliers and handling them\n",
    "\n",
    "We're using the IQR method to detect outliers in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "152c7669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "OUTLIER DETECTION for train dataset\n",
      "==================================================\n",
      "ApplicantYears: 0 outliers detected\n",
      "AnnualEarnings: 0 outliers detected\n",
      "RequestedSum: 0 outliers detected\n",
      "TrustMetric: 0 outliers detected\n",
      "WorkDuration: 0 outliers detected\n",
      "ActiveAccounts: 0 outliers detected\n",
      "OfferRate: 0 outliers detected\n",
      "RepayPeriod: 0 outliers detected\n",
      "DebtFactor: 0 outliers detected\n",
      "RiskFlag: 23753 outliers detected\n",
      "\n",
      "==================================================\n",
      "OUTLIER DETECTION for test dataset\n",
      "==================================================\n",
      "ApplicantYears: 0 outliers detected\n",
      "AnnualEarnings: 0 outliers detected\n",
      "RequestedSum: 0 outliers detected\n",
      "TrustMetric: 0 outliers detected\n",
      "WorkDuration: 0 outliers detected\n",
      "ActiveAccounts: 0 outliers detected\n",
      "OfferRate: 0 outliers detected\n",
      "RepayPeriod: 0 outliers detected\n",
      "DebtFactor: 0 outliers detected\n"
     ]
    }
   ],
   "source": [
    "def detect_outliers_iqr(df, columns=None, threshold=1.5):\n",
    "\n",
    "    if columns is None:\n",
    "        columns = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "    outlier_indices = []\n",
    "\n",
    "    for col in columns:\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "\n",
    "        lower_bound = Q1 - threshold * IQR\n",
    "        upper_bound = Q3 + threshold * IQR\n",
    "\n",
    "        outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)].index\n",
    "        outlier_indices.extend(outliers)\n",
    "\n",
    "        print(f\"{col}: {len(outliers)} outliers detected\")\n",
    "\n",
    "    return list(set(outlier_indices))\n",
    "\n",
    "\"\"\"Detect outliers using IQR method\"\"\"\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"OUTLIER DETECTION for train dataset\")\n",
    "print(\"=\"*50)\n",
    "# indices of outlers in the dataset\n",
    "outliers_train = detect_outliers_iqr(train_df)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"OUTLIER DETECTION for test dataset\")\n",
    "print(\"=\"*50)\n",
    "# indices of outlers in the dataset\n",
    "outliers_test = detect_outliers_iqr(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ae84c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preprocessed datasets saved to c:\\Users\\gathi\\projects\\ML-Project-2\\Binary-Class Problem\\datasets\\preprocessed\n"
     ]
    }
   ],
   "source": [
    "save_dir = dataset_dir.joinpath(\"preprocessed\")\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "train_df.to_csv(save_dir.joinpath(\"train_preprocessed.csv\"), index=False)\n",
    "test_df.to_csv(save_dir.joinpath(\"test_preprocessed.csv\"), index=False)\n",
    "print(f\"\\nPreprocessed datasets saved to {save_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17092aaf",
   "metadata": {},
   "source": [
    "## Things left to do\n",
    "\n",
    "Do the following preprocessing steps based on your requirements.\n",
    "\n",
    "1) Feature Engineering\n",
    "2) Feature Encoding\n",
    "4) Encoding Categorical Variables\n",
    "3) Feature Scaling\n",
    "4) Feature Selection\n",
    "5) Data Validation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
